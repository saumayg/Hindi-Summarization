{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c9wMXc7UV59W"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M7Vfr-nuWA7y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting indic\n",
      "  Downloading indic-0.1.2.tar.gz (6.3 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic) (1.26.3)\n",
      "Requirement already satisfied: pandas>=0.12 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic) (2.1.4)\n",
      "Collecting matplotlib>=1.3 (from indic)\n",
      "  Using cached matplotlib-3.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.13 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic) (1.3.2)\n",
      "Requirement already satisfied: scipy>=0.13 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic) (1.11.4)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=1.3->indic)\n",
      "  Using cached contourpy-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=1.3->indic)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=1.3->indic)\n",
      "  Using cached fonttools-4.47.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (157 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=1.3->indic)\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from matplotlib>=1.3->indic) (23.2)\n",
      "Collecting pillow>=8 (from matplotlib>=1.3->indic)\n",
      "  Using cached pillow-10.2.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=1.3->indic)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from matplotlib>=1.3->indic) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib>=1.3->indic)\n",
      "  Using cached importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from pandas>=0.12->indic) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from pandas>=0.12->indic) (2023.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from scikit-learn>=0.13->indic) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from scikit-learn>=0.13->indic) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=1.3->indic) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=1.3->indic) (1.16.0)\n",
      "Using cached matplotlib-3.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Using cached contourpy-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.47.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pillow-10.2.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Building wheels for collected packages: indic\n",
      "  Building wheel for indic (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for indic: filename=indic-0.1.2-py3-none-any.whl size=10060 sha256=6216dd27817c98d65851dbbf8f027ff9a7cee6cec43b886f7fddc22aee45ea27\n",
      "  Stored in directory: /home/g100may/.cache/pip/wheels/99/46/ae/5111371e0c7d7160c689f9f6cee321acd45a4e32d4c419dd4a\n",
      "Successfully built indic\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib, indic\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.47.0 importlib-resources-6.1.1 indic-0.1.2 kiwisolver-1.4.5 matplotlib-3.8.2 pillow-10.2.0 pyparsing-3.1.1\n",
      "Requirement already satisfied: indic-nlp-library in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (0.92)\n",
      "Requirement already satisfied: sphinx-argparse in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic-nlp-library) (0.4.0)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: morfessor in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic-nlp-library) (2.0.6)\n",
      "Requirement already satisfied: pandas in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic-nlp-library) (2.1.4)\n",
      "Requirement already satisfied: numpy in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from indic-nlp-library) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from pandas->indic-nlp-library) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from pandas->indic-nlp-library) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from pandas->indic-nlp-library) (2023.4)\n",
      "Requirement already satisfied: sphinx>=1.2.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx-argparse->indic-nlp-library) (7.2.6)\n",
      "Requirement already satisfied: docutils<0.21 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx-rtd-theme->indic-nlp-library) (0.20.1)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.7)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.9)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.6)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.14 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.17.2)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.14.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
      "Requirement already satisfied: imagesize>=1.3 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.25.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n",
      "Requirement already satisfied: packaging>=21.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from importlib-metadata>=4.8->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from Jinja2>=3.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.11.17)\n",
      "Requirement already satisfied: transformers in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting wxconv\n",
      "  Downloading wxconv-1.0.0.0-py2.py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pbr<3.0,>=2.0 (from wxconv)\n",
      "  Downloading pbr-2.1.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six<2.0,>=1.12 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from wxconv) (1.16.0)\n",
      "Installing collected packages: pbr, wxconv\n",
      "Successfully installed pbr-2.1.0 wxconv-1.0.0.0\n",
      "Collecting polyglot_tokenizer\n",
      "  Downloading polyglot_tokenizer-2.0.2-py2.py3-none-any.whl (323 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pbr<3.0,>=2.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from polyglot_tokenizer) (2.1.0)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from polyglot_tokenizer) (1.16.0)\n",
      "Installing collected packages: polyglot_tokenizer\n",
      "Successfully installed polyglot_tokenizer-2.0.2\n",
      "Collecting torch_sparse\n",
      "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[17 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-jysuzskv/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-jysuzskv/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 295, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-jysuzskv/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 480, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-jysuzskv/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 311, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'torch'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25hCollecting torch_geometric\n",
      "  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (1.26.3)\n",
      "Requirement already satisfied: scipy in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (1.11.4)\n",
      "Requirement already satisfied: jinja2 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from torch_geometric) (5.9.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->torch_geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->torch_geometric) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from requests->torch_geometric) (2023.11.17)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.4.0\n",
      "Collecting torch_scatter\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[17 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-uouu6i1s/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-uouu6i1s/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 295, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-uouu6i1s/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 480, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-uouu6i1s/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 311, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'torch'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install indic\n",
    "!pip install indic-nlp-library\n",
    "!pip install transformers\n",
    "!pip install wxconv\n",
    "!pip install polyglot_tokenizer\n",
    "\n",
    "!pip install torch_sparse\n",
    "!pip install torch_geometric\n",
    "!pip install torch_scatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "slN2FHIfWDVV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/g100may/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import sys\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from indicnlp.tokenize import sentence_tokenize\n",
    "from indicnlp.tokenize import indic_tokenize \n",
    "from nltk.tokenize import word_tokenize\n",
    "import polyglot_tokenizer\n",
    "from polyglot_tokenizer import Tokenizer\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import xlrd\n",
    "import csv\n",
    "from wxconv import WXC\n",
    "\n",
    "import gensim\n",
    "import sklearn\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # The path to the local git repo for Indic NLP library\n",
    "# INDIC_NLP_LIB_HOME=r\"C:\\Users\\ankunchu\\Documents\\src\\indic_nlp_library\"\n",
    "# # The path to the local git repo for Indic NLP Resources\n",
    "# INDIC_NLP_RESOURCES=r\"C:\\Users\\ankunchu\\Documents\\src\\indic_nlp_resources\"\n",
    "# sys.path.append(r'{}\\src'.format(INDIC_NLP_LIB_HOME))# The path to the local git repo for Indic NLP library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "F4pl_1DFhBKe"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import transformers\n",
    "from transformers import BertConfig, BertModel\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lH5ZHC1Kv4-8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at subbareddyiiit/BERT-NLP and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#BERT model\n",
    "# Download model and configuration from S3 and cache.\n",
    "\n",
    "bert_model = BertModel.from_pretrained('subbareddyiiit/BERT-NLP')\n",
    "config = BertConfig.from_pretrained(\"subbareddyiiit/BERT-NLP\",output_attentions=True)  \n",
    "bert_tk = AutoTokenizer.from_pretrained(\"subbareddyiiit/BERT-NLP\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fU4gEGm9kpbf"
   },
   "outputs": [],
   "source": [
    "def get_wx_sentence(sent):\n",
    "  con = WXC(order='utf2wx',lang='hin')  \n",
    "  wx_sentence = con.convert(sent)  \n",
    "  return wx_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nUKb5nBmx8aH"
   },
   "outputs": [],
   "source": [
    "#returns a 768(for bert) size embedding \n",
    "\n",
    "def bert_sentence_embedding(sentence, model):\n",
    "  # wx_sent = get_wx_sentence(sentence)\n",
    "  tokens = bert_tk.tokenize(sentence)\n",
    "  count = 0\n",
    "  for each_word in tokens:\n",
    "    if (each_word=='.' or each_word=='-' or each_word=='\\\\' or each_word=='_' or each_word==',' or each_word==\"'\" or each_word=='[' or each_word==']' or each_word=='(' or each_word==')' or each_word=='*' or each_word==';' or each_word=='|'  or each_word==':'  or each_word=='-'or each_word=='?'or each_word=='!' or each_word==\"\\/\"):\n",
    "      count += 1\n",
    "    if (each_word=='▁.' or each_word=='▁-' or each_word=='▁\\\\' or each_word=='▁_' or each_word=='▁,' or each_word==\"▁'\" or each_word=='▁[' or each_word=='▁]' or each_word=='▁(' or each_word=='▁)' or each_word=='▁*' or each_word=='▁;' or each_word=='▁|'  or each_word=='▁:'  or each_word=='▁-'or each_word=='▁?'or each_word=='▁!' or each_word==\"▁\\/\"):\n",
    "      count += 1\n",
    "  if (count >= (len(tokens)/2)):\n",
    "    return np.zeros((768))\n",
    "    \n",
    "  sent = bert_tk.encode(sentence)\n",
    "  sent = torch.tensor(sent).unsqueeze(0)\n",
    "  with torch.no_grad():\n",
    "    output = model(sent)\n",
    "  # final_output = output.pooler_output.detach().numpy()\n",
    "  last_hidden_state = output.last_hidden_state\n",
    "  sentence_embedding = last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "  return sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UXuF_nTbWRJl"
   },
   "outputs": [],
   "source": [
    "class Document:\n",
    "  def __init__(self, doc_num):\n",
    "    self.doc_num = doc_num\n",
    "      \n",
    "  def add_clustermap(self, labels, k):\n",
    "    temp = {}\n",
    "    for i in range(k):\n",
    "      temp[i] = []\n",
    "    for i,each_label in enumerate(labels):\n",
    "      temp[each_label].append(i)\n",
    "    self.cluster_map = temp\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "QDooO4KCx78j"
   },
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import sentence_tokenize\n",
    "\n",
    "#pre-processing step \n",
    "\n",
    "def pre_process_sentences(sentences):\n",
    "  sentences = sentences.replace('\\u200c','')\n",
    "  sentences = sentences.replace('\\\\u200c','')\n",
    "  sentences = sentences.replace('\\\\u200d','')\n",
    "  # sentences = sentences.split('[')[1]\n",
    "  # sentences = sentences.split(']')[0]\n",
    "  # sentences = re.split(\"', '|', \\\"'/|\\\", '|\\\", \\\"\",  sentences)\n",
    "  sentences = sentence_tokenize.sentence_split(sentences, lang='hi')\n",
    "  # n = len(sentences)\n",
    "  # if (sentences[0][0] == \"'\"):\n",
    "  #   sentences[0] = sentences[0].split(\"'\")[1]\n",
    "  # elif (sentences[0][0] == '\"'):\n",
    "  #   sentences[0] = sentences[0].split('\"')[1]\n",
    "  # else:\n",
    "  #   print(\"character = \", sentences[0][0])\n",
    "  \n",
    "  # m = len(sentences[n-1])\n",
    "  # if (sentences[n-1][m-1] == \"'\"):\n",
    "  #   sentences[n-1] = sentences[n-1].split(\"'\")[0]    \n",
    "  # elif (sentences[n-1][m-1] == '\"'):\n",
    "  #   sentences[n-1] = sentences[n-1].split('\"')[0] \n",
    "  # else:\n",
    "  #   print(\"ending character = \", sentences[n-1][m-1])\n",
    "  return sentences\n",
    "\n",
    "\n",
    "# def pre_process_highlights(sentences):\n",
    "#   sentences = sentences.replace('\\u200c','')\n",
    "#   sentences = sentences.replace('\\\\u200c','')\n",
    "#   sentences = sentences.replace('\\\\u200d','')\n",
    "#   # sentences = sentences.split('[')[1]\n",
    "#   # sentences = sentences.split(']')[0]\n",
    "#   sentences = sentences.split(\"', '\")\n",
    "#   sentences[0] = sentences[0].split(\"'\")[1]\n",
    "#   n = len(sentences)\n",
    "#   sentences[n-1] = sentences[n-1].split(\"'\")[0]\n",
    "#   return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "v_da00lMndOW"
   },
   "outputs": [],
   "source": [
    "def get_clusters( embeds, k):\n",
    "  clustering = SpectralClustering(n_clusters=k, assign_labels=\"discretize\", random_state=0).fit(embeds)\n",
    "  return clustering.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "S4e5b5AfnBSz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#dataset you want to try upon\n",
    "final_data = '../Datasets/Hindi_summarization/XLSum/hindi_train.jsonl'\n",
    "\n",
    "# data_reader = csv.reader(final_data)\n",
    "data = pd.read_json(final_data, lines=True)\n",
    "k = 3   #no.of clusters\n",
    "emb_dim = 768     \n",
    "\n",
    "data = data[:10]\n",
    "\n",
    "all_documents = []\n",
    "# print(data.shape)\n",
    "\n",
    "# # print(data_reader)\n",
    "for i in data.index:\n",
    "#     print(row)\n",
    "    # try:\n",
    "        # if count ==0:\n",
    "        #   count=1\n",
    "        #   continue\n",
    "        doc = Document(i)\n",
    "        # highlights = pre_process_highlights(data['text'][i])\n",
    "        sentences = pre_process_sentences(data['text'][i])\n",
    "        # setattr(doc, \"highlights\", highlights)\n",
    "        setattr(doc, \"raw_sentences\", sentences)\n",
    "        \n",
    "        embeds = []\n",
    "        for sent in sentences:\n",
    "          temp = bert_sentence_embedding(sent, bert_model)\n",
    "          embeds.append(temp)\n",
    "        setattr(doc, \"sent_embeds\", embeds)\n",
    "        if (len(embeds)!=len(sentences)):\n",
    "          print(\"sentence improper = \", sentences)\n",
    "          raise ValueError\n",
    "        all_documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"और वो भी न तो 'बराक' की वजह से और न ही उनकी वजह से जिनके साथ वो 'मन की बात' करके लौटे हैं.\",\n",
       " 'इसके पीछे सीधा हाथ है भारतीय हिंदू मां-बाप से पैदा हुए लुइज़ियाना के गवर्नर बॉबी जिंदल का, जो पैदा हुए थे पियूष जिंदल, लेकिन हाई स्कूल तक पहुंचते-पहुंचते उन्होंने अपना धर्म बदला और हो गए बॉबी जिंदल.',\n",
       " 'बेचारे मां-बाप अभी भी हिंदू ही हैं.',\n",
       " 'ये सब तो ठीक है, इसमें भारत के अच्छे दिन कहां से आ गए?',\n",
       " 'बस एक इजाद की वजह से और वो है फ़ेयर एंड हैंडसम!',\n",
       " 'भारतीय अमरीका या अमरीकी जिंदल साहब को सही मायने में ख़ुद को अमरीकी कहलाने की ऐसी ख़्वाहिश है कि उनकी एक पेंटिंग में उन्हें बिल्कुल गोरा और वो भी बिल्कुल वैसा, जिसे हम गोरा-गोरा कहते हैं न, वैसा दिखाया गया है.',\n",
       " \"समाप्त इश्तहारों की मानें तो 'त्वचा में दूध जैसी गोराई' तो फ़ेयर एंड हैंडसम से ही लाई जा सकती है.\",\n",
       " 'तो नज़र रखिएगा, आपके पड़ोस की दुकान से फ़ेयर एंड हैंडसम ग़ायब होने को है क्योंकि उसकी खेप की खेप अब लुइज़ियाना पहुंचेगी और भारत में डॉलरों की बरसात होगी.',\n",
       " 'फ़ेयर एंड हैंडसम के शेयर आसमान चूमेंगे.',\n",
       " 'क्योंकि तस्वीर के जैसा दिखने के लिए जिंदल साहब फ़ेयर एंड हैंडसम का ही तो सहारा लेंगे.',\n",
       " \"तो 'मेक इन इंडिया फ़ॉर लुइज़ियाना' का राग अलापना शुरू कीजिए और प्लीज़, लुइज़ियाना को लुधियाना मत लिख दीजिएगा, जिंदल साहब की शान में गुस्ताख़ी कर देंगे आप.\",\n",
       " 'ख़ैर, जब उनकी ये बिल्कुल गुलाबी गोराई वाली पेंटिंग सोशल मीडिया पर आई तो किम कारदाशियां का इंटरनेट का रिकॉर्ड टूटने को आया.',\n",
       " 'अब लोग तो ज़ाहिर हैं, जिंदल साहब के दिल की बात समझे बग़ैर मज़ाक़ उड़ाने लगे सोशल मीडिया पर.',\n",
       " 'उनकी पब्लिसिटी टीम ने कहा कि ये उन्होंने ख़ुद नहीं बनवाया है, किसी चाहनेवाले ने बना कर दिया है.',\n",
       " 'और फिर एक नई पेंटिंग जारी की गई जिसमें उनका रंग ऐसा लग रहा है जैसे कोई गोरा इंसान थोड़ी सी धूप खाकर लौटा हो.',\n",
       " 'राष्ट्रपति पद की उम्मीदवारी दरअसल, जिंदल साहब इस बार रिपब्लिकन पार्टी की तरफ़ से राष्ट्रपति पद की उम्मीदवारी की रेस में शामिल हैं.',\n",
       " \"लेकिन इसके पहले कि आप देसी टीवी चैनल्स की तरह चीख़ना शुरू कर दें कि 'एक इंडियन अब व्हाइट हाउस की रेस में', मैं आपकी उम्मीदों पर इस ठंडे मौसम में ठंडा पानी डाल देता हूं.\",\n",
       " 'क्योंकि जिंदल साहब चीख़-चीख़ कर ये भी एलान कर रहे हैं कि उन्हें इंडियन-अमरीकन नहीं कहा जाए, सिर्फ़ अमरीकन कहा जाए.',\n",
       " 'उनके राज्य की एक भारतीय मूल की महिला ने मुझे बताया था कि गवर्नर होने के बावजूद वो होली, दिवाली, ईद, मुहर्रम किसी मौक़े पर देसियों के आस-पास नहीं दिखना पसंद करते.',\n",
       " 'और तो और उन्होंने मुसलमानों के ख़िलाफ़ ऐसी जिहाद छेड़ी है कि प्रवीण तोगड़िया भी शर्मा जाएंगे.',\n",
       " 'पहले तो उन्होंने कहा कि यूरोप में कई ऐसे इलाक़े हैं जिनपर मुसलमानों ने क़ब्ज़ा कर लिया है और वहां शरिया क़ानून चलता है और अमरीका में भी वही हाल होनेवाला है.',\n",
       " 'मुसलमान घुल-मिल कर नहीं रहते, क्योंकि उनका एजेंडा है ख़ामोशी से अमरीका को इस्लामी मुल्क बनाना.',\n",
       " 'सबका साथ, सबका विकास इस बात का कोई सबूत नहीं पेश कर पाए तो क्या हुआ, जिस कट्टरपंथी इसाई तबक़े को लुभाने की कोशिश कर रहे हैं वो वहां हीरो तो बन गए.',\n",
       " 'इन दिनों ऐसी संस्थाओं के इर्द-गिर्द नज़र आ रहे हैं वो जिनका नारा है कि जो अमरीका आए वो इसाई बन जाए तभी सही मायने में वो अमरीकी कहलाएगा.',\n",
       " 'वैसे मुझे समझ में ये बात नहीं आ रही कि जिंदल साहब किसकी सलाह पर चल रहे हैं.',\n",
       " 'अपने क्लास के टॉपर थे, रोड्स स्कॉलर हैं और कुछ साल पहले तक उन्हें रिपब्लिकन पार्टी के ओबामा की तरह देखा जा रहा था.',\n",
       " 'थोड़ा सा हिसाब-किताब लगाते तो नज़र आ जाता कि अमरीका में सिर्फ़ एक तबक़े के वोट से सदर बनना तो दूर की बात अपनी पार्टी की उम्मीदवारी मिलने की भी उम्मीद नहीं की जा सकती.',\n",
       " 'अमरीका में बात नहीं समझ में आ रही हो तो भारत में ही देख लेते.',\n",
       " 'गुजरात के मोदीजी और दिल्ली के मोदीजी में जो फ़र्क़ है, उसकी बारीकी ज़रा समझ लें तो बस चांदी ही चांदी है.',\n",
       " \"छोटा सा मंत्र है 'सबका साथ, सबका विकास' दिन भर रटिए और फिर वोट बटोरिए.\",\n",
       " '(बीबीसी हिन्दी के एंड्रॉएड ऐप के लिए यहां क्लिक करें.',\n",
       " 'आप हमें फ़ेसबुक और ट्विटर पर भी फ़ॉलो कर सकते हैं.',\n",
       " ')']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents[0].raw_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_documents[0].raw_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0YZIdhBomAC"
   },
   "source": [
    "#Getting document representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "44C64HYpQnlj"
   },
   "outputs": [],
   "source": [
    "# getting document embeddings by summation of sentence representations\n",
    "\n",
    "def get_document_embedding(all_documents):       \n",
    "  doc_embeds = []\n",
    "  for each_doc in all_documents:\n",
    "    doc_embedding = np.zeros(emb_dim)\n",
    "    for sent in each_doc.sent_embeds:\n",
    "        # print(sent)\n",
    "        doc_embedding = np.add(doc_embedding, sent)\n",
    "        # except:\n",
    "            # print(sent == [])\n",
    "            # break\n",
    "    doc_embedding = doc_embedding/len(each_doc.sent_embeds)\n",
    "    doc_embeds.append(doc_embedding)\n",
    "  return doc_embeds\n",
    "\n",
    "doc_embeds1 = get_document_embedding(all_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBkBN9cqqLWE"
   },
   "source": [
    "#Padding sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2TntsKF4oQRC"
   },
   "outputs": [],
   "source": [
    "def get_max_length(all_documents):\n",
    "  max_l = 0\n",
    "  for each_doc in all_documents:\n",
    "    if max_l < len(each_doc.sent_embeds):\n",
    "      max_l = len(each_doc.sent_embeds)\n",
    "  print(max_l)\n",
    "  return max_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "LUyzRC6NovZt"
   },
   "outputs": [],
   "source": [
    "def pad_sentences(max_length):\n",
    "  for i in range(len(all_documents)):\n",
    "    req = max_length -len(all_documents[i].sent_embeds)\n",
    "    if req >0:\n",
    "      added = np.zeros((req, emb_dim))\n",
    "      all_documents[i].sent_embeds.extend(added)\n",
    "      add_labels = [-1 for i in range(req)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "oMHXbdrXqXda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "max_num_of_sent = get_max_length(all_documents)\n",
    "pad_sentences(max_num_of_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VKthy22tUiZ"
   },
   "source": [
    "# Document Graph Construction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TlI5Bo42tTSm"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "def get_cosine_similarity(sent_a, sent_b):\n",
    "  return (1 - spatial.distance.cosine(sent_a, sent_b))\n",
    "\n",
    "def doc_edge_index(x, threshold):\n",
    "  n = len(x)\n",
    "  pos_edge_index_r = []\n",
    "  pos_edge_index_c = []\n",
    "  neg_edge_index_r = []\n",
    "  neg_edge_index_c = []\n",
    "  for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "      try:\n",
    "        sent1 = x[i]\n",
    "        sent2 = x[j]\n",
    "        score = get_cosine_similarity( sent1, sent2)\n",
    "      except:\n",
    "        print(\"error = \", sent1, sent2)\n",
    "        raise ValueError\n",
    "      if (score > threshold):\n",
    "        pos_edge_index_r.append(i)\n",
    "        pos_edge_index_c.append(j)\n",
    "        pos_edge_index_r.append(j)\n",
    "        pos_edge_index_c.append(i)\n",
    "      else:\n",
    "        neg_edge_index_r.append(i)\n",
    "        neg_edge_index_c.append(j)\n",
    "        neg_edge_index_r.append(j)\n",
    "        neg_edge_index_c.append(i)\n",
    "  pos_edge_index = torch.tensor([pos_edge_index_r, pos_edge_index_c])\n",
    "  neg_edge_index = torch.tensor([neg_edge_index_r, neg_edge_index_c])\n",
    "  return pos_edge_index, neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1gKtDC9vtcTc"
   },
   "outputs": [],
   "source": [
    "#edge index for document noded graph\n",
    "\n",
    "doc_threshold = 0.997\n",
    "doc_embeds_pos_edge_index, doc_embeds_neg_edge_index = doc_edge_index(doc_embeds1, doc_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGZpKcX8qAWx"
   },
   "source": [
    "# **Document Encoding**\n",
    " > Document graph constructed is passed through GAE_doc to obtain document representations.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "r_-KPEaTe4eT"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "215WbW22p_Aw"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Document_Encoder_GAE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Document_Encoder_GAE, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "pOMrlCH1p9MQ"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "lA52_KR5qsfD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer =  RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      " starting epoch =  0\n",
      "loss =  tensor(34.5388, grad_fn=<AddBackward0>)\n",
      " loss decreased (inf --> 34.538776).  Saving model ...\n",
      " starting epoch =  1\n",
      "loss =  tensor(34.5388, grad_fn=<AddBackward0>)\n",
      " loss decreased (34.538776 --> 34.538776).  Saving model ...\n",
      " starting epoch =  2\n",
      "loss =  tensor(34.5388, grad_fn=<AddBackward0>)\n",
      " loss decreased (34.538776 --> 34.538776).  Saving model ...\n",
      " starting epoch =  3\n",
      "loss =  tensor(34.5388, grad_fn=<AddBackward0>)\n",
      " loss decreased (34.538776 --> 34.538776).  Saving model ...\n",
      " starting epoch =  4\n",
      "loss =  tensor(34.5388, grad_fn=<AddBackward0>)\n",
      " loss decreased (34.538776 --> 34.538776).  Saving model ...\n",
      " starting epoch =  5\n",
      "loss =  tensor(34.5388, grad_fn=<AddBackward0>)\n",
      " loss decreased (34.538776 --> 34.538776).  Saving model ...\n",
      " starting epoch =  6\n",
      "loss =  tensor(32.2142, grad_fn=<AddBackward0>)\n",
      " loss decreased (34.538776 --> 32.214230).  Saving model ...\n",
      " starting epoch =  7\n",
      "loss =  tensor(5.8708, grad_fn=<AddBackward0>)\n",
      " loss decreased (32.214230 --> 5.870813).  Saving model ...\n",
      " starting epoch =  8\n",
      "loss =  tensor(4.0549, grad_fn=<AddBackward0>)\n",
      " loss decreased (5.870813 --> 4.054929).  Saving model ...\n",
      " starting epoch =  9\n",
      "loss =  tensor(1.7746, grad_fn=<AddBackward0>)\n",
      " loss decreased (4.054929 --> 1.774640).  Saving model ...\n",
      " starting epoch =  10\n",
      "loss =  tensor(1.3936, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.774640 --> 1.393633).  Saving model ...\n",
      " starting epoch =  11\n",
      "loss =  tensor(1.3515, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.393633 --> 1.351450).  Saving model ...\n",
      " starting epoch =  12\n",
      "loss =  tensor(1.3468, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.351450 --> 1.346775).  Saving model ...\n",
      " starting epoch =  13\n",
      "loss =  tensor(1.3585, grad_fn=<AddBackward0>)\n",
      " starting epoch =  14\n",
      "loss =  tensor(1.3347, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.346775 --> 1.334722).  Saving model ...\n",
      " starting epoch =  15\n",
      "loss =  tensor(1.3472, grad_fn=<AddBackward0>)\n",
      " starting epoch =  16\n",
      "loss =  tensor(1.3322, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.334722 --> 1.332194).  Saving model ...\n",
      " starting epoch =  17\n",
      "loss =  tensor(1.3173, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.332194 --> 1.317348).  Saving model ...\n",
      " starting epoch =  18\n",
      "loss =  tensor(1.3153, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.317348 --> 1.315320).  Saving model ...\n",
      " starting epoch =  19\n",
      "loss =  tensor(1.3082, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.315320 --> 1.308235).  Saving model ...\n",
      " starting epoch =  20\n",
      "loss =  tensor(1.3183, grad_fn=<AddBackward0>)\n",
      " starting epoch =  21\n",
      "loss =  tensor(1.3080, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.308235 --> 1.307980).  Saving model ...\n",
      " starting epoch =  22\n",
      "loss =  tensor(1.2910, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.307980 --> 1.290973).  Saving model ...\n",
      " starting epoch =  23\n",
      "loss =  tensor(1.2842, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.290973 --> 1.284184).  Saving model ...\n",
      " starting epoch =  24\n",
      "loss =  tensor(1.2748, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.284184 --> 1.274770).  Saving model ...\n",
      " starting epoch =  25\n",
      "loss =  tensor(1.2792, grad_fn=<AddBackward0>)\n",
      " starting epoch =  26\n",
      "loss =  tensor(1.3108, grad_fn=<AddBackward0>)\n",
      " starting epoch =  27\n",
      "loss =  tensor(1.2793, grad_fn=<AddBackward0>)\n",
      " starting epoch =  28\n",
      "loss =  tensor(1.2728, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.274770 --> 1.272810).  Saving model ...\n",
      " starting epoch =  29\n",
      "loss =  tensor(1.2790, grad_fn=<AddBackward0>)\n",
      " starting epoch =  30\n",
      "loss =  tensor(1.3039, grad_fn=<AddBackward0>)\n",
      " starting epoch =  31\n",
      "loss =  tensor(1.2853, grad_fn=<AddBackward0>)\n",
      " starting epoch =  32\n",
      "loss =  tensor(1.2762, grad_fn=<AddBackward0>)\n",
      " starting epoch =  33\n",
      "loss =  tensor(1.2749, grad_fn=<AddBackward0>)\n",
      " starting epoch =  34\n",
      "loss =  tensor(1.2918, grad_fn=<AddBackward0>)\n",
      " starting epoch =  35\n",
      "loss =  tensor(1.2511, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.272810 --> 1.251134).  Saving model ...\n",
      " starting epoch =  36\n",
      "loss =  tensor(1.2491, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.251134 --> 1.249089).  Saving model ...\n",
      " starting epoch =  37\n",
      "loss =  tensor(1.2455, grad_fn=<AddBackward0>)\n",
      " loss decreased (1.249089 --> 1.245517).  Saving model ...\n",
      " starting epoch =  38\n",
      "loss =  tensor(1.2726, grad_fn=<AddBackward0>)\n",
      " starting epoch =  39\n",
      "loss =  tensor(1.2650, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "doc_gae_model = GAE(Document_Encoder_GAE(768, 256))\n",
    "doc_optimizer = torch.optim.RMSprop(doc_gae_model.parameters() , lr=1e-4, weight_decay=5e-4)\n",
    "print(\"optimizer = \", doc_optimizer)\n",
    "\n",
    "#number of epochs\n",
    "train_loss_min = np.Inf\n",
    "for t in range(40):\n",
    "    print(\" starting epoch = \", t)\n",
    "    doc_gae_model.train()\n",
    "    doc_optimizer.zero_grad()\n",
    "    doc_em = torch.FloatTensor(doc_embeds1)\n",
    "    output = doc_gae_model.encode(doc_em, doc_embeds_pos_edge_index)\n",
    "    train_loss = doc_gae_model.recon_loss(output, doc_embeds_pos_edge_index)\n",
    "    train_loss.backward()\n",
    "    doc_optimizer.step()\n",
    "    doc_gae_model.eval()\n",
    "\n",
    "    checkpoint = {\n",
    "            'epoch': t + 1,\n",
    "            'valid_loss_min': train_loss,\n",
    "            'state_dict1': doc_gae_model.state_dict(),\n",
    "            'optimizer': doc_optimizer.state_dict(),}\n",
    "\n",
    "    save_ckp(checkpoint, False, 'doc_joint_checkpoint1.pt', 'doc_joint_best_model1.pt')\n",
    "    print(\"loss = \", train_loss)\n",
    "    if train_loss <= train_loss_min:\n",
    "      print(' loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min,train_loss))\n",
    "      save_ckp(checkpoint, True,  'doc_joint_checkpoint2.pt',  'doc_joint_best_model2.pt')\n",
    "      train_loss_min = train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "y9itNxSj1ACH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "final_doc_embeds = doc_gae_model.encode(torch.FloatTensor(doc_embeds1), doc_embeds_pos_edge_index )\n",
    "print(final_doc_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvmBoVTHqEZo"
   },
   "source": [
    "# **Sentence Encoding and Summary Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5XyTslFqYCE"
   },
   "source": [
    "# Sentence Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "r1Ba18fmqDJQ"
   },
   "outputs": [],
   "source": [
    "def sent_edge_index(x, threshold):\n",
    "  n = len(x.raw_sentences)\n",
    "  pos_edge_index_r = []\n",
    "  pos_edge_index_c = []\n",
    "  neg_edge_index_r = []\n",
    "  neg_edge_index_c = []\n",
    "  for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "      try:\n",
    "        sent1 = x.sent_embeds[i]\n",
    "        sent2 = x.sent_embeds[j]\n",
    "        score = get_cosine_similarity( sent1, sent2)\n",
    "      except:\n",
    "        print(\"error = \", x.sent_embeds.shape)\n",
    "        raise ValueError\n",
    "      if (score > threshold):\n",
    "        pos_edge_index_r.append(i)\n",
    "        pos_edge_index_c.append(j)\n",
    "        pos_edge_index_r.append(j)\n",
    "        pos_edge_index_c.append(i)\n",
    "      else:\n",
    "        neg_edge_index_r.append(i)\n",
    "        neg_edge_index_c.append(j)\n",
    "        neg_edge_index_r.append(j)\n",
    "        neg_edge_index_c.append(i)\n",
    "  pos_edge_index = torch.tensor([pos_edge_index_r, pos_edge_index_c])\n",
    "  neg_edge_index = torch.tensor([neg_edge_index_r, neg_edge_index_c])\n",
    "  return pos_edge_index, neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Aq4YmusUqCsP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g100may/MTP/NEA-ATS/py3.9-pytorch/lib/python3.9/site-packages/scipy/spatial/distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "sent_threshold = 0.99\n",
    "\n",
    "for i,each_doc in enumerate(all_documents):\n",
    "  pos_edge_index, neg_edge_index =sent_edge_index(each_doc, sent_threshold)\n",
    "  setattr(each_doc, \"pos_edge_index\", pos_edge_index)\n",
    "  setattr(each_doc, \"neg_edge_index\", neg_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEzGZBf8hdEU"
   },
   "source": [
    "#Sentence Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fwBLHFG7gkRC"
   },
   "outputs": [],
   "source": [
    "class Encoder_GAE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder_GAE, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeVPVFasNYoq"
   },
   "source": [
    "#Clustering and Cluster Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "a2jbs1priv53"
   },
   "outputs": [],
   "source": [
    "class RNN_model(torch.nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, layer_dim):\n",
    "    super(RNN_model, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.layer_dim = layer_dim\n",
    "    self.input_dim = input_dim\n",
    "    \n",
    "    self.rnn = torch.nn.GRU(self.input_dim, self.hidden_dim, self.layer_dim, batch_first=True)\n",
    "\n",
    "  \n",
    "  def forward(self, x, sent_embeds):\n",
    "    #modify the document to get the proper input\n",
    "    final_input = []\n",
    "    lengths = []\n",
    "\n",
    "    len_sent = len(x.raw_sentences)\n",
    "    copy_sent = sent_embeds[:len_sent].clone().detach()\n",
    "    labels = get_clusters(copy_sent, k)\n",
    "    x.add_clustermap(labels, k)\n",
    "    req = max_num_of_sent -len(x.raw_sentences)\n",
    "    if req >0:\n",
    "      add_labels = [-1 for i in range(req)]\n",
    "      labels = np.append(labels, add_labels)\n",
    "    setattr(x, \"labels\", labels)\n",
    "\n",
    "    map = x.cluster_map\n",
    "\n",
    "    for key,value in map.items():\n",
    "      temp = torch.empty((len(value),self.input_dim,))\n",
    "      for l,each_val in enumerate(value):\n",
    "        temp[l] = sent_embeds[each_val]\n",
    "      if (len(value) == 0):\n",
    "        lengths.append(1)\n",
    "        final_input.append(torch.zeros(self.input_dim))\n",
    "      else:\n",
    "        final_input.append(temp)\n",
    "        lengths.append(len(value))\n",
    "\n",
    "    b = torch.nn.utils.rnn.pad_sequence(final_input, batch_first=True)    \n",
    "    my_packed_seq = torch.nn.utils.rnn.pack_padded_sequence(b, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "    # Initialize hidden state with zeros  (change initialization)\n",
    "    h0 = torch.zeros(self.layer_dim, len(final_input), self.hidden_dim)\n",
    "    out, hn = self.rnn(my_packed_seq, h0)\n",
    "    unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "\n",
    "    #get proper document wise cluster embeddings\n",
    "    final_clu_embeds = torch.zeros((k,self.hidden_dim))\n",
    "\n",
    "    for j in range(k):\n",
    "      final_clu_embeds[j] = unpacked[j,unpacked_len[j]-1,:]\n",
    "    return final_clu_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i1lZMowDPXz"
   },
   "source": [
    "#Summary generation\n",
    "The actual model in order to find the top k sentences in the document. \n",
    "\n",
    "Gets the relevance and position scores of each sentence and then finds the top k sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HmIcz3iLp17p"
   },
   "outputs": [],
   "source": [
    "class Summary_model(torch.nn.Module):\n",
    "  def __init__(self,Dim, H1):\n",
    "    super(Summary_model, self).__init__()\n",
    "    self.linear1 = torch.nn.utils.weight_norm(torch.nn.Linear(Dim, H1), name='weight')\n",
    "    \n",
    "\n",
    "  def get_salience_scores(self, doc_scores, labels):\n",
    "    clu_scores = torch.zeros(k+1)\n",
    "    new_scores = torch.zeros(len(doc_scores))\n",
    "    for i in range(len(doc_scores)):\n",
    "      clus_num = labels[i]\n",
    "      clu_scores[clus_num+1] = torch.add(clu_scores[clus_num+1], doc_scores[i])\n",
    "    clu_scores[0] = 0         #padded sentences\n",
    "\n",
    "    for i in range(len(doc_scores)):\n",
    "      clus_num = labels[i]\n",
    "      if (clus_num+1==0) :\n",
    "        new_scores[i] = 0.0\n",
    "      else:\n",
    "        new_scores[i] = torch.div(doc_scores[i],(clu_scores[clus_num+1]))\n",
    "    return new_scores\n",
    "  \n",
    "\n",
    "  def append_cluster_embeds(self, labels, sentences, clu_embed):\n",
    "    size_em = 128     #cluster embedding size (hidden dimension)\n",
    "    size = 256+size_em  #gcn output sentence embedding     \n",
    "    append_embeds = torch.zeros( (sentences.shape[0], size ) )\n",
    "    \n",
    "    for i,each_sent in enumerate(sentences):\n",
    "      l = labels[i]\n",
    "      if (l == -1):\n",
    "        cl_em = torch.zeros(size_em)\n",
    "        temp = torch.cat(( torch.tensor(sentences[i]), torch.zeros(size_em, requires_grad=True)  ), 0)\n",
    "      else:\n",
    "        temp = torch.cat((torch.tensor(sentences[i]), clu_embed[l]), 0)\n",
    "      append_embeds[i] = temp\n",
    "    return append_embeds\n",
    "  \n",
    "  def get_position_score(self,x):\n",
    "    pos_scores = torch.zeros(len(x.sent_embeds))\n",
    "    N = len(x.raw_sentences)\n",
    "    for i in range(N):\n",
    "      value = (i+1)/(N ** (1./3))\n",
    "      pos_scores[i] = max(0.5, math.exp(-value))\n",
    "    return pos_scores\n",
    "\n",
    "  \n",
    "  def forward(self, x, cluster_embeds, sent_embeds):\n",
    "    #access the embeddings\n",
    "    final_embeds = self.append_cluster_embeds(x.labels, sent_embeds, cluster_embeds)\n",
    "    scores = self.linear1(final_embeds)\n",
    "    scores = torch.tanh(scores)\n",
    "    sal_scores = self.get_salience_scores(scores, x.labels)\n",
    "    pos_scores = self.get_position_score(x)\n",
    "    final_scores = torch.add(0.4*sal_scores, 0.6*pos_scores)\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-4ZjSK0Jmur7"
   },
   "outputs": [],
   "source": [
    "class Ensemble_model(torch.nn.Module):\n",
    "  def __init__(self, model1,model2):\n",
    "    super(Ensemble_model, self).__init__()\n",
    "    self.model1 = model1\n",
    "    self.model2 = model2\n",
    "\n",
    "  def forward(self, x, sent_embeds):\n",
    "    x1 = self.model1(x, sent_embeds)\n",
    "    x2 = self.model2(x, x1, sent_embeds) \n",
    "    return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTAghbK9qUhB"
   },
   "source": [
    "#Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "CgP6ysLviSul"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "#Contrastive Loss function\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, output1, output2, target, size_average=True):\n",
    "        distances = (output2 - output1).pow(2).sum(0)  # squared distances\n",
    "        losses = 0.5 * (float(target) * distances + float(1 + -1 * target) * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "\n",
    "\n",
    "def logcosh(y_t, y_prime_t):\n",
    "  ey_t = y_t - y_prime_t\n",
    "  return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "JaCo0J1nLu7V"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def my_loss_function(y_pred, y_true, x, sent_embeds):\n",
    "\n",
    "  summary = torch.zeros(256, requires_grad=True)\n",
    "  final_scores = torch.zeros((len(y_pred),257))\n",
    " \n",
    "  for i in range(len(y_pred)):\n",
    "    final_scores[i][0] = y_pred[i]\n",
    "    final_scores[i][1:] = torch.tensor(sent_embeds[i], requires_grad=True)  \n",
    "  \n",
    "  sorted, indices = torch.sort(final_scores, 0, descending=True)\n",
    "  val = 0\n",
    "  for i in range(top_k_sent):\n",
    "    val = val + sorted[i,0]\n",
    "\n",
    "  for i in range(top_k_sent):\n",
    "    summary = torch.add(summary, torch.mul(sorted[i, 1:], sorted[i,0]) ) \n",
    "  num = top_k_sent*val\n",
    "  summary = torch.div(summary,num)\n",
    "  con_loss = ContrastiveLoss(0.5)\n",
    "  loss1 = con_loss(y_true,summary, 1.0 )\n",
    "  return loss1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ovN1pdzBCQ4"
   },
   "source": [
    "#Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-jFyt1JRX1lY"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_documents, final_doc_embeds.detach(), test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "N8G5oCU8EQZm"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hlvUwW6ZLwi9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer =  RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      " starting epoch =  0\n",
      "loss =  tensor(7.6229)\n",
      " loss decreased (inf --> 7.622878).  Saving model ...\n",
      " starting epoch =  1\n",
      "loss =  tensor(2.5904)\n",
      " loss decreased (7.622878 --> 2.590438).  Saving model ...\n",
      " starting epoch =  2\n",
      "loss =  tensor(2.0781)\n",
      " loss decreased (2.590438 --> 2.078110).  Saving model ...\n",
      " starting epoch =  3\n",
      "loss =  tensor(1.7405)\n",
      " loss decreased (2.078110 --> 1.740538).  Saving model ...\n",
      " starting epoch =  4\n",
      "loss =  tensor(1.6228)\n",
      " loss decreased (1.740538 --> 1.622820).  Saving model ...\n",
      " starting epoch =  5\n",
      "loss =  tensor(1.8793)\n",
      " starting epoch =  6\n",
      "loss =  tensor(1.6386)\n",
      " starting epoch =  7\n",
      "loss =  tensor(1.6334)\n",
      " starting epoch =  8\n",
      "loss =  tensor(1.6299)\n",
      " starting epoch =  9\n",
      "loss =  tensor(1.5979)\n",
      " loss decreased (1.622820 --> 1.597908).  Saving model ...\n",
      " starting epoch =  10\n",
      "loss =  tensor(2.3108)\n",
      " starting epoch =  11\n",
      "loss =  tensor(1.6402)\n",
      " starting epoch =  12\n",
      "loss =  tensor(1.7803)\n",
      " starting epoch =  13\n",
      "loss =  tensor(1.6270)\n",
      " starting epoch =  14\n",
      "loss =  tensor(1.7171)\n",
      " starting epoch =  15\n",
      "loss =  tensor(1.6256)\n",
      " starting epoch =  16\n",
      "loss =  tensor(1.6277)\n",
      " starting epoch =  17\n",
      "loss =  tensor(1.8524)\n",
      " starting epoch =  18\n",
      "loss =  tensor(1.6264)\n",
      " starting epoch =  19\n",
      "loss =  tensor(1.6802)\n",
      " starting epoch =  20\n",
      "loss =  tensor(1.9789)\n",
      " starting epoch =  21\n",
      "loss =  tensor(2.6685)\n",
      " starting epoch =  22\n",
      "loss =  tensor(1.7609)\n",
      " starting epoch =  23\n",
      "loss =  tensor(1.6393)\n",
      " starting epoch =  24\n",
      "loss =  tensor(1.6194)\n",
      " starting epoch =  25\n",
      "loss =  tensor(1.6277)\n",
      " starting epoch =  26\n",
      "loss =  tensor(1.6861)\n",
      " starting epoch =  27\n",
      "loss =  tensor(1.6358)\n",
      " starting epoch =  28\n",
      "loss =  tensor(1.6534)\n",
      " starting epoch =  29\n",
      "loss =  tensor(2.1915)\n",
      " starting epoch =  30\n",
      "loss =  tensor(1.8775)\n",
      " starting epoch =  31\n",
      "loss =  tensor(1.8509)\n",
      " starting epoch =  32\n",
      "loss =  tensor(1.6804)\n",
      " starting epoch =  33\n",
      "loss =  tensor(1.6255)\n",
      " starting epoch =  34\n",
      "loss =  tensor(1.8125)\n",
      " starting epoch =  35\n",
      "loss =  tensor(1.7216)\n",
      " starting epoch =  36\n",
      "loss =  tensor(1.7048)\n",
      " starting epoch =  37\n",
      "loss =  tensor(1.6840)\n",
      " starting epoch =  38\n",
      "loss =  tensor(1.6343)\n",
      " starting epoch =  39\n",
      "loss =  tensor(1.9359)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "Dim = 768  \n",
    "top_k_sent = 3\n",
    "input_dim = Dim   \n",
    "hidden_dim = 128 #cluster dimension  \n",
    "layer_dim = 2\n",
    "gcn_out_dim = 256 #encoder bottle neck expected dimension \n",
    "\n",
    "#with gae\n",
    "gaemodel = GAE(Encoder_GAE(Dim, gcn_out_dim))\n",
    "model1 = RNN_model(gcn_out_dim, hidden_dim, layer_dim)\n",
    "model2 = Summary_model(gcn_out_dim+hidden_dim, 1)\n",
    "final_model = Ensemble_model( model1, model2)\n",
    "all_params = list(final_model.parameters()) + list(gaemodel.parameters())\n",
    "optimizer = torch.optim.RMSprop(all_params, lr=5e-4, weight_decay=5e-4)\n",
    "\n",
    "print(\"optimizer = \", optimizer)\n",
    "\n",
    "#number of epochs\n",
    "\n",
    "train_loss_min = np.Inf\n",
    "for t in range(40):\n",
    "    print(\" starting epoch = \", t)\n",
    "    train_loss = 0.0\n",
    "    final_model.train()\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "      try:\n",
    "        optimizer.zero_grad()\n",
    "        sentences_em = torch.FloatTensor(X_train[i].sent_embeds)\n",
    "        output = gaemodel.encode(sentences_em, X_train[i].pos_edge_index)\n",
    "        recon_loss = gaemodel.recon_loss(output, X_train[i].pos_edge_index)\n",
    "        y_pred = final_model( X_train[i], output )\n",
    "        # print(y_pred.shape)\n",
    "        trail_doc_embeds = np.zeros( (len(all_documents),gcn_out_dim ) )\n",
    "        loss = my_loss_function( y_pred, y_train[i] , X_train[i], output)  \n",
    "        Joint_loss = loss+recon_loss\n",
    "        Joint_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = train_loss + ( (1 / (i + 1)) * (Joint_loss.data - train_loss))\n",
    "      except:\n",
    "        print(\"error here = \",i)\n",
    "\n",
    "    final_model.eval()\n",
    "\n",
    "    checkpoint = {\n",
    "            'epoch': t + 1,\n",
    "            'valid_loss_min': train_loss,\n",
    "            'state_dict1': final_model.state_dict(),\n",
    "            'state_dict2':gaemodel.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),}\n",
    "\n",
    "    save_ckp(checkpoint, False, 'joint_checkpoint2.pt', 'joint_best_model2.pt')\n",
    "    print(\"loss = \", train_loss)\n",
    "    if train_loss <= train_loss_min:\n",
    "      print(' loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min,train_loss))\n",
    "      save_ckp(checkpoint, True,  'joint_checkpoint2.pt',  'joint_best_model2.pt')\n",
    "      train_loss_min = train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ICASSP Joint_loss CODE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
